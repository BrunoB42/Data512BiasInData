{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24668224-510d-4ce0-ba0d-bd8107b7e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "\n",
    "import requests\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ef0b92-0142-48ce-ab6c-65feb0e1615f",
   "metadata": {},
   "source": [
    "# HW2 Bias in Wikipedia Article Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c6179-4fac-4d60-916d-01c92e703c08",
   "metadata": {},
   "source": [
    "Among the numerous articles hosted on Wikipedia and curated by its users are various articles covering the lives and careers of notable politicians from around the world. For many data-focused political research projects, Wikipedia's information serves as an easily accessible and widely repected data source. However, not all Wikipedia articles are created equal.\n",
    "\n",
    "As part of its community curation systems, Wikipedia allows for every article to be assigned a quality rating indicated how thorough, well-reseached, and transparent it content and sources are. Due to the fact that this process requires significant human effort, not all articles have such a grade assigned to them. However, Wikipedia's ORES API allows for quality rating to be assigned through a machine learning model trained on the prior quality ratings given by Wikipedia's community.\n",
    "\n",
    "Through the use of this system, it becomes reasonable to ask the questions that this analysis will seek to answer: Is there a bias in quality of Wikipedia politician articles across different countries and regions? And if so, what patterns describe the nature of of this bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f949c9-36ec-4658-a75b-e1106c575240",
   "metadata": {},
   "source": [
    "### Part 1 - Obtaining Article and Population Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f6e57f-3b59-4e6b-8ae1-d8ed205f9cee",
   "metadata": {},
   "source": [
    "#### Article Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e088e1-70aa-466a-be56-b69e7254e2ab",
   "metadata": {},
   "source": [
    "Before any article quality data for each politician can be obtained, the politicians must first be matched to their respective articles. The page info for each article contains the last revision ID for that article. This ID can be used by the ORES API in order to assign a quality score to a specific instance of a given article, as they are frequently revised.\n",
    "\n",
    "In order to obtain this, the Wikipedia category of politicians by nationality was crawled to obtain a list of articles on political figures across the world. This list will be imported below and cleaned of any inappropriate or unusable values so that the list can be used to query the Page Info API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f112f37d-e72e-4dea-a437-77e341bb22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in list of wikipedia politician articles by country\n",
    "politicians_df = pd.read_csv(\"politicians_by_country_AUG.2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e13a2b-94fe-4a3f-a401-3948bb459964",
   "metadata": {},
   "source": [
    "When inspecting the article titles in the crawled dataset, a small problem can be seen. Many of the articles in the list are not articles about politicians but instead articles about political offices. In order to address this, articles referring to specific political positions will be removed from the article list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538b361-43cc-4b4a-aaee-a8cd3d6b2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing non-politician articles from dataset\n",
    "invalid_article_string_list = [\"Presid\", \"Ministry\", \"Ministers\"]\n",
    "politicians_df = politicians_df[~politicians_df.name.str.contains('|'.join(invalid_article_string_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae8f6f-82ec-460f-9680-92a01babed2a",
   "metadata": {},
   "source": [
    "A secondary glance at the list will reveal a much more significant issue to our analysis. Several political figures have separate articles for their policial histories and their overall lives. In particular, politicians from impoverished, obscure, or otherwise poorly-documented countries seem to be much more likely to have their articles split in this way. Less than 20 such articles appear to exist in the dataset, but this trend is worth noting for future analysis.\n",
    "\n",
    "With the list of articles cleaned, the page info can now be obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45714784-af0f-4cab-9879-f28026672ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "API_HEADER_AGENT = 'User-Agent'\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "REQUEST_HEADERS = {\n",
    "    'User-Agent': '<brun0b42@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2024'\n",
    "}\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for\n",
    "# what can be included. If you don't want any this can simply be the empty string\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"talkid|url|watched|watchers\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # to simplify this should be a single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72700741-499d-4eef-9c9f-08a35e8537af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_pageinfo_per_article(article_title = None, \n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT, \n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "    \n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['titles'] = article_title\n",
    "\n",
    "    if not request_template['titles']:\n",
    "        raise Exception(\"Must supply an article title to make a pageinfo request.\")\n",
    "\n",
    "    if API_HEADER_AGENT not in headers:\n",
    "        raise Exception(f\"The header data should include a '{API_HEADER_AGENT}' field that contains your UW email address.\")\n",
    "\n",
    "    if 'uwnetid@uw' in headers[API_HEADER_AGENT]:\n",
    "        raise Exception(f\"Use your UW email address in the '{API_HEADER_AGENT}' field.\")\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "65660f8e-182f-4a72-a545-f8fc8fe4e23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page info data for:  Denis Walker 7141 / 7142                                                         71 / 7142                 \r"
     ]
    }
   ],
   "source": [
    "# Obtaining page info for each politician article\n",
    "page_info_list = []\n",
    "for article_num, article_title in enumerate(politicians_df.name):\n",
    "    print(\"Getting page info data for: \", article_title, str(article_num) + \" / \" + str(len(politicians_df.name)), \"                \", end=\"\\r\")\n",
    "    info = request_pageinfo_per_article(article_title)\n",
    "    info_dict = next(iter(info['query']['pages'].values()))\n",
    "    page_info_list = page_info_list + [info_dict]\n",
    "\n",
    "# Compiling page info responses into a DataFrame\n",
    "politicians_page_info_df = pd.DataFrame(page_info_list)\n",
    "# Saving the page info responses into a json file\n",
    "#politicians_page_info_df.to_json(\"politicians_page_info.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e613514-6a40-42c8-a565-55b6c6daead5",
   "metadata": {},
   "source": [
    "Looking at the data obtained from the Page Info API, one small problem in need of cleaning stands out. Eight of the articles sent to the Page Info for an info request led to an API response with missing values for both ID and revision ID. This can likely be attributed to the article lacking english language page info. Regardless of the cause, the revision ID is necessary to obtain the ORES quality estimates and thus these data points must be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5d0c712f-cb69-4a78-b444-037f8f36c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing data for articles will NaN id and lastrevid entries\n",
    "politicians_page_info_df[politicians_page_info_df.lastrevid.isna()]\n",
    "politicians_page_info_df = politicians_page_info_df[~politicians_page_info_df.lastrevid.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af2679-89ac-478e-877c-f9d0f5f8061c",
   "metadata": {},
   "source": [
    "With the Page Info API data obtained, there is one more dataset to be brought in before moving to the ORES API. In order to effectively compare the quality statistics for articles across countries and regions, it is important to have metrics for the populations in each country. Aside from countries that have been home to exceptionally important recent events, it can generally be assumed that the number of politicians in and the amount of attention paid to any given country will be proportional to its size. As such, population and region data will be brought in from the Population Reference Bureau's world population datasheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0cedd387-17c4-478f-af01-4de2bef3df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in population dataset\n",
    "populations_df = pd.read_csv(\"population_by_country_AUG.2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288d1caf-1b2f-43d8-ad02-530348e7a91b",
   "metadata": {},
   "source": [
    "### Part 2 - Generating Article Quality Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a79e21-fa06-4418-aa9b-fd4200cafd99",
   "metadata": {},
   "source": [
    "With the revision IDs and article titles obtained, the ORES WingLift API can now be queried. By providing an API access token and a revision ID, the ORES API will take the specific revision of the given article and calculate its estimated quality score.\n",
    "\n",
    "Since this process is limited to a maximum of 5000 requests per hour and some articles lack the page info necessary to generate a predicted score, it is important to catch exceptions and http error responses during this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6358b2f5-9f41-4169-99e0-2387b6b353c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#    The current LiftWing ORES API endpoint and prediction model\n",
    "#\n",
    "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
    "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
    "\n",
    "#\n",
    "#    The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "#    come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
    "#\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = ((60.0*60.0)/5000.0)-API_LATENCY_ASSUMED  # The key authorizes 5000 requests per hour\n",
    "\n",
    "#    When making automated requests we should include something that is unique to the person making the request\n",
    "#    This should include an email - your UW email would be good to put in there\n",
    "#    \n",
    "#    Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "#    as part of the header too\n",
    "#\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': \"<{email_address}>, University of Washington, MSDS DATA 512 - AUTUMN 2024\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer {access_token}\"\n",
    "}\n",
    "#\n",
    "#    This is a template for the parameters that we need to supply in the headers of an API request\n",
    "#\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"\",         # your email address should go here\n",
    "    'access_token'  : \"\"          # the access token you create will need to go here\n",
    "}\n",
    "\n",
    "#\n",
    "#    A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring example\n",
    "#\n",
    "ARTICLE_REVISIONS = { 'Bison':1085687913 , 'Northern flicker':1086582504 , 'Red squirrel':1083787665 , 'Chinook salmon':1085406228 , 'Horseshoe bat':1060601936 }\n",
    "\n",
    "#\n",
    "#    This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "#\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}\n",
    "\n",
    "#\n",
    "#    These are used later - Include your own username and API token to perform the necessary function calls\n",
    "#\n",
    "USERNAME = \"YourUserName\"\n",
    "ACCESS_TOKEN = \"YourAccessToken\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "583199e3-02e4-45b3-9fc1-b0d24bdefa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    PROCEDURES/FUNCTIONS\n",
    "#\n",
    "\n",
    "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
    "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT, \n",
    "                                   model_name = API_ORES_EN_QUALITY_MODEL, \n",
    "                                   request_data = ORES_REQUEST_DATA_TEMPLATE, \n",
    "                                   header_format = REQUEST_HEADER_TEMPLATE, \n",
    "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
    "    \n",
    "    #    Make sure we have an article revision id, email and token\n",
    "    #    This approach prioritizes the parameters passed in when making the call\n",
    "    if article_revid:\n",
    "        request_data['rev_id'] = article_revid\n",
    "    if email_address:\n",
    "        header_params['email_address'] = email_address\n",
    "    if access_token:\n",
    "        header_params['access_token'] = access_token\n",
    "    \n",
    "    #   Making a request requires a revision id - an email address - and the access token\n",
    "    if not request_data['rev_id']:\n",
    "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
    "    if not header_params['email_address']:\n",
    "        raise Exception(\"Must provide an 'email_address' value\")\n",
    "    if not header_params['access_token']:\n",
    "        raise Exception(\"Must provide an 'access_token' value\")\n",
    "    \n",
    "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
    "    request_url = endpoint_url.format(model_name=model_name)\n",
    "    \n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free data\n",
    "        # source like ORES - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        #response = requests.get(request_url, headers=headers)\n",
    "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0c5d81da-82ef-4b42-a789-4d974bf05a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page info data for:  Denis Walker 7133 / 7134                                                         64 / 7134                 \r"
     ]
    }
   ],
   "source": [
    "ORES_quality_list = []\n",
    "ORES_request_failed_list = []\n",
    "ORES_request_http_error_list = []\n",
    "for article_num, article_info in enumerate(zip(politicians_page_info_df.title, politicians_page_info_df.lastrevid.astype(int))):\n",
    "    print(\"Getting page info data for: \", article_info[0], str(article_num) + \" / \" + str(len(politicians_page_info_df.title)), \"                \", end=\"\\r\")\n",
    "    # Obtaining raw ORES response data for each article\n",
    "    try:\n",
    "        score = request_ores_score_per_article(article_revid=article_info[1],\n",
    "                                               email_address=\"brunob42@uw.edu\",\n",
    "                                               access_token=ACCESS_TOKEN)\n",
    "    except Exception as excep:\n",
    "        # Catching errors where the ORES request function throws an unexpected in-script error\n",
    "        ORES_request_failed_list = ORES_request_failed_list + [article_info[0]]\n",
    "    # Unpacking densely nested article quality information\n",
    "    try:\n",
    "        score_values = next(iter(next(iter(next(iter(next(iter(score.values()))['scores'].values())).values())).values()))['probability']\n",
    "    except :\n",
    "        # Catching cases where the ORES request encounters an HTTP request timeout or missing data\n",
    "        ORES_request_http_error_list = ORES_request_http_error_list + [article_info[0]]\n",
    "    # Adding in article and revision data to identify scores\n",
    "    score_values['title'] = article_info[0]\n",
    "    score_values['lastrevid'] = article_info[1]\n",
    "    # Adding entry to list of ORES predictions\n",
    "    ORES_quality_list = ORES_quality_list + [score_values]\n",
    "\n",
    "ORES_score_df = pd.DataFrame(ORES_quality_list)\n",
    "#ORES_score_df.to_json(\"ORES_quality_scores.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73fdcb-b664-4827-9565-2b8186c47d9f",
   "metadata": {},
   "source": [
    "### Part 3: Data Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316884b-b95d-44d3-82be-658d951cc760",
   "metadata": {},
   "source": [
    "With all three datasets now obtained, it is necessary to combine them together so that the page info, population/region, and ORES score data can all be associated with their respective politician articles.\n",
    "\n",
    "To begin with, any articles that lack a quality estimate will be removed as they cannot be used for this analysis. Approximately ten articles are dropped in this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ba2a1c1d-e491-4fc3-82fe-96338ecbd1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing entries that could not be assigned an ORES quality estimate\n",
    "politicians_df = politicians_df[politicians_df.name.isin(ORES_score_df.title)]\n",
    "ORES_score_df = ORES_score_df[ORES_score_df.title.isin(politicians_df.name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e012d-faf1-44f9-8603-ca71f7c57adb",
   "metadata": {},
   "source": [
    "Following this, the quality and page info dataset can be neatly joined on their shared article name columns.\n",
    "\n",
    "To simplify later analysis of the assigned quality scores, a column will be added to the merged dataset containing the quality category that has the highest probability assigned to it by the ORES ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "e268469d-f269-40ea-9809-b82857909284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding ORES quality data to politician dataset\n",
    "ORES_score_df = ORES_score_df.rename({\"title\":\"name\"}, axis=1)\n",
    "politicians_score_df = pd.merge(politicians_df, ORES_score_df, on='name')\n",
    "# Adding column denoting most likely quality score category\n",
    "politicians_score_df['score'] = politicians_score_df[politicians_score_df.columns[3:-4]].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bf3605-5949-495c-9228-40ae9f315c10",
   "metadata": {},
   "source": [
    "Now, the population and region data must be added. To accomplish this, each article's country will be matched to the region associated with it in the population file's hierarchy. This can be done due to the simple fact that each region in the population dataset is written in all caps and comes immediately before the names of the countries associated with it. Thus, the region can be obtained by finding the country name in the dataset and working back up the list until a region name is found\n",
    "\n",
    "Then, the population for that country will be obtained by finding the matching row in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "0ecd17bc-bb0f-4f27-b06b-508cdc49e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_from_country(country):\n",
    "    region = None\n",
    "    # Looping through geographic regions to find country location\n",
    "    for geo_index, geography in enumerate(populations_df.Geography):\n",
    "        if geography == country:\n",
    "            current_region_index = geo_index\n",
    "            # Working back up the index to find region from country name\n",
    "            while populations_df.Geography[current_region_index] != populations_df.Geography[current_region_index].upper():\n",
    "                current_region_index = current_region_index - 1\n",
    "            region = populations_df.Geography[current_region_index]\n",
    "            break\n",
    "    return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "5508b83d-b5b3-4955-8fad-c9b2ac757632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population_from_region(region):\n",
    "    # Obtaining population value associated with given region\n",
    "    return float(populations_df[populations_df.Geography == region].Population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "dfb719ae-012b-4318-a518-c6a246907491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning regions to every politician based on country\n",
    "politicians_score_df['region'] = politicians_score_df.country.apply(get_region_from_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53246e2d-e761-41ce-b99a-30e46bd5807d",
   "metadata": {},
   "source": [
    "While attempting to map the datasets together, it can be seen that 143 of the articles sadly lack a corresponding region in the population dataset. These articles are all assigned to one of three countries and should be saved to record the reason for their absence in the analysis before continuing with the merge of the three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "7d7b4566-6654-4978-92ef-091882d6e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining and saving list of countries that did not have a matching region in the population dataset\n",
    "regionless_politicians_df = politicians_score_df[politicians_score_df['region'].isna()]\n",
    "pd.Series(regionless_politicians_df.country.unique()).to_csv(\"wp_countries-no_match.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "58c160fb-8c3f-4fbe-933d-42d8e2ae1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing regionless politicians from final dataset\n",
    "politicians_score_df = politicians_score_df[~politicians_score_df['region'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "4058e7e0-756e-4d97-be1a-bf6337f985b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_1412\\452031569.py:3: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  return float(populations_df[populations_df.Geography == region].Population)\n"
     ]
    }
   ],
   "source": [
    "# Assigning population by region\n",
    "politicians_score_df['population'] = politicians_score_df.country.apply(get_population_from_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2dbc21-3b83-4a95-816b-cec538fda395",
   "metadata": {},
   "source": [
    "With the three datasets combined, only a small number of final steps remain. In order to simplify future analysis, a boolean column containing the value of whether or not a given article was classified as 'high quality' (`FA` or `GA` in the ORES API) should be added to the dataset, the columns should be renamed for clarity, and the dataset should be saved as a csv for ease of use in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "3d354fa5-0fea-4973-8a82-ae5c202d051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_high_quality(quality):\n",
    "    if quality == 'GA' or quality == 'FA':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f6af50fb-0660-4ebf-8d01-32608fd05b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding high quality column denoting a predicted quality of GA or FA\n",
    "politicians_score_df['high_quality'] = politicians_score_df.score.apply(is_high_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "df83e8fe-3e18-4d4c-8d9f-bc31a8d91550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaing columns for clarity\n",
    "politicians_score_df = politicians_score_df.rename({'name':'article_title',\n",
    "                                                    'lastrevid':'revision_id',\n",
    "                                                    'score':'article_quality'},\n",
    "                                                  axis = 1)\n",
    "# Saving final dataset\n",
    "politicians_score_df.to_csv('wp_politicians_by_country.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c1828-e0a3-4697-8e05-5a1f4caafeb1",
   "metadata": {},
   "source": [
    "### Part 4: Analysis and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6994a5-f3bb-4a95-b2ec-387c7455248c",
   "metadata": {},
   "source": [
    "With the final dataset now obtained, the six main questions of this Wikipedia politician bias analysis can be answered.\n",
    "\n",
    "The first two of these questions are:\n",
    "* What 10 countries have the most politician articles per capita?\n",
    "\n",
    "and\n",
    "\n",
    "* What 10 countries have the _fewest_ politician articles per capita?\n",
    "\n",
    "To answer these first two questions, the datset can be grouped by country and population so that the count of articles within each country can be calculated and divided by each country's population to obtain the number of articles per million people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b0a451c1-ae53-4525-ab4a-fb44cd2bc4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>num_articles</th>\n",
       "      <th>articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>0.1</td>\n",
       "      <td>33</td>\n",
       "      <td>330.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Federated States of Micronesia</td>\n",
       "      <td>0.1</td>\n",
       "      <td>14</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>0.1</td>\n",
       "      <td>13</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Barbados</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>0.6</td>\n",
       "      <td>38</td>\n",
       "      <td>63.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Seychelles</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Maldives</td>\n",
       "      <td>0.6</td>\n",
       "      <td>33</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>0.8</td>\n",
       "      <td>44</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Samoa</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            country  population  num_articles  \\\n",
       "4               Antigua and Barbuda         0.1            33   \n",
       "51   Federated States of Micronesia         0.1            14   \n",
       "93                 Marshall Islands         0.1            13   \n",
       "149                           Tonga         0.1            10   \n",
       "12                         Barbados         0.3            25   \n",
       "98                       Montenegro         0.6            38   \n",
       "125                      Seychelles         0.1             6   \n",
       "90                         Maldives         0.6            33   \n",
       "17                           Bhutan         0.8            44   \n",
       "121                           Samoa         0.2             8   \n",
       "\n",
       "     articles_per_capita  \n",
       "4             330.000000  \n",
       "51            140.000000  \n",
       "93            130.000000  \n",
       "149           100.000000  \n",
       "12             83.333333  \n",
       "98             63.333333  \n",
       "125            60.000000  \n",
       "90             55.000000  \n",
       "17             55.000000  \n",
       "121            40.000000  "
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting number of high quality politician articles (GA or FA) for each country\n",
    "articles_by_country_df = politicians_score_df.groupby(['country','population']).count().loc[:,'article_title'].reset_index()\n",
    "# Calculating number of high quality articles per million people in each country\n",
    "articles_by_country_df['articles_per_capita'] = articles_by_country_df.article_title / articles_by_country_df.population\n",
    "articles_by_country_df = articles_by_country_df.rename({'article_title':'num_articles'}, axis=1)\n",
    "# Generating table of 10 highest lowest per capita countries (excluding countries with 0 population)\n",
    "articles_by_country_df.sort_values('articles_per_capita', ascending=False).head(12).iloc[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c146a1e9-1a37-4251-a515-edf30996ece6",
   "metadata": {},
   "source": [
    "Looking at the above table, it can be seen that nearly all countries with a high per-capita article count achieve this due to their low populaations. Regardless of how small these countries are, their politicians possess a baseline level of importance that ensures that they will have articles written about them on Wikipedia.\n",
    "\n",
    "Sorting this dataset in ascending order instead, we obtain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "5ebe40b5-8f84-4ee6-b1ef-6ab390783660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>num_articles</th>\n",
       "      <th>articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>China</td>\n",
       "      <td>1411.3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.011337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Ghana</td>\n",
       "      <td>34.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.087977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>India</td>\n",
       "      <td>1428.6</td>\n",
       "      <td>151</td>\n",
       "      <td>0.105698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>36.9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.135501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>20.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.148515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Norway</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Israel</td>\n",
       "      <td>9.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.204082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>105.2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.304183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Cote d'Ivoire</td>\n",
       "      <td>30.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.323625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Mozambique</td>\n",
       "      <td>33.9</td>\n",
       "      <td>12</td>\n",
       "      <td>0.353982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country  population  num_articles  articles_per_capita\n",
       "31           China      1411.3            16             0.011337\n",
       "57           Ghana        34.1             3             0.087977\n",
       "66           India      1428.6           151             0.105698\n",
       "122   Saudi Arabia        36.9             5             0.135501\n",
       "164         Zambia        20.2             3             0.148515\n",
       "108         Norway         5.5             1             0.181818\n",
       "70          Israel         9.8             2             0.204082\n",
       "45           Egypt       105.2            32             0.304183\n",
       "37   Cote d'Ivoire        30.9            10             0.323625\n",
       "100     Mozambique        33.9            12             0.353982"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating table of 10 lowest articles per capita countries\n",
    "articles_by_country_df.sort_values('articles_per_capita', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38e1100-8e70-4271-91d9-f13a181d04cb",
   "metadata": {},
   "source": [
    "Since the countries with a _high_ per-capita article count achieve their status through a low population count, it should come as no surprise that the countries with a _low_ per-capita article count achieve _their_ status with a high population count. Being comprised primarily of countries with some combination of sizable populations or exceptionally few articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b00755-a007-4905-919f-2a9edc6f0b3e",
   "metadata": {},
   "source": [
    "The second pair of questions to be answered by this analysis are:\n",
    "* What 10 countries have the most _high-quality_ politician articles per capita?\n",
    "\n",
    "and\n",
    "\n",
    "* What 10 countries have the fewest _high-quality_ politician articles per capita?\n",
    "\n",
    "To answer these questions, the dataset can once again be grouped by country and population so that the total number of high quality articles for that country can be calculated and divided by the total population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "46f09728-ef5f-4d52-9ab9-ae6204d74a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>high_quality</th>\n",
       "      <th>quality_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4</td>\n",
       "      <td>1.379310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Kosovo</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Latvia</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Serbia</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Belarus</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.326087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             country  population  high_quality  quality_per_capita\n",
       "98        Montenegro         0.6             2            3.333333\n",
       "86        Luxembourg         0.7             1            1.428571\n",
       "85         Lithuania         2.9             4            1.379310\n",
       "76            Kosovo         1.7             2            1.176471\n",
       "1            Albania         2.7             3            1.111111\n",
       "107  North Macedonia         1.8             1            0.555556\n",
       "80            Latvia         1.9             1            0.526316\n",
       "124           Serbia         6.6             3            0.454545\n",
       "13           Belarus         9.2             3            0.326087\n",
       "95           Moldova         3.4             1            0.294118"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting number of high quality politician articles (GA or FA) for each country\n",
    "high_quality_by_country_df = politicians_score_df.groupby(['country','population']).sum('high_quality').loc[:,'high_quality'].reset_index()\n",
    "# Calculating number of high quality articles per million people in each country\n",
    "high_quality_by_country_df['quality_per_capita'] = high_quality_by_country_df.high_quality / high_quality_by_country_df.population\n",
    "# Generating table of 10 highest quality per capita countries\n",
    "high_quality_by_country_df.sort_values('quality_per_capita', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85184a2c-4d83-4c74-af64-3aa2a6737a04",
   "metadata": {},
   "source": [
    "Much like with the results for the raw number of articles-per-capita, the countries with a high number of high-quality articles per capita uniformly have moderate or small populations. However, these countries _also_ have a relatively large number of high_quality articles in each. It may not initially appear to be the case, as each country only has a 1-4 articles each, but it turns out that exceptionally few articles in the dataset (approximately 90 in total) were assigned a high quality score.\n",
    "\n",
    "Sorting this result dataset in ascending order instead, we can obtain the obvious answer to the inverse question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "013770ef-6576-4c6e-bb16-9eabfe9784b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>high_quality</th>\n",
       "      <th>quality_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>42.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Paraguay</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Palestinian Territory</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>240.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Oman</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Norway</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Niger</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Nicaragua</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   country  population  high_quality  quality_per_capita\n",
       "0              Afghanistan        42.4             0                 0.0\n",
       "117               Portugal        10.5             0                 0.0\n",
       "114               Paraguay         6.2             0                 0.0\n",
       "113       Papua New Guinea         9.5             0                 0.0\n",
       "111  Palestinian Territory         5.5             0                 0.0\n",
       "110               Pakistan       240.5             0                 0.0\n",
       "109                   Oman         5.0             0                 0.0\n",
       "108                 Norway         5.5             0                 0.0\n",
       "105                  Niger        27.2             0                 0.0\n",
       "104              Nicaragua         6.8             0                 0.0"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating table of 10 lowest quality per capita countries\n",
    "high_quality_by_country_df.sort_values('quality_per_capita', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dabef05-8b4e-4933-8bfb-b292b9442c31",
   "metadata": {},
   "source": [
    "Since very few high_quality articles exist in the dataset, countless countries have 0 high quality articles whatsoever, and thus they are all tied for the lowest per-capita count of high-quality articles about politicians."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e63625-a81b-4c3d-afe8-5c238f1f592d",
   "metadata": {},
   "source": [
    "Thus far, these analyses have been focused on comparisons across countries. However the final two questions to be answered are:\n",
    "\n",
    "* What regions have the most politician articles per capita?\n",
    "\n",
    "and\n",
    "\n",
    "* What regions have the most _high-quality_ politician articles per capita?\n",
    "\n",
    "To answer these questions, the dataset can be grouped by region and the sum of both populations and high-quality article counts can be obtained across each region while the counts of politician articles overall can be calculated separately. The article and high-quality article totals can then be divided by the population totals to obtain the per-capita values for both articles overall and high-quality articles specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "0b1c4b35-b75b-44b9-9c13-64d5c8d21a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_count</th>\n",
       "      <th>population</th>\n",
       "      <th>articles_per_capita</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OCEANIA</th>\n",
       "      <td>71</td>\n",
       "      <td>110.8</td>\n",
       "      <td>0.640794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORTHERN EUROPE</th>\n",
       "      <td>196</td>\n",
       "      <td>1194.5</td>\n",
       "      <td>0.164085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARIBBEAN</th>\n",
       "      <td>215</td>\n",
       "      <td>1369.7</td>\n",
       "      <td>0.156969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CENTRAL AMERICA</th>\n",
       "      <td>193</td>\n",
       "      <td>1477.5</td>\n",
       "      <td>0.130626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CENTRAL ASIA</th>\n",
       "      <td>118</td>\n",
       "      <td>2203.5</td>\n",
       "      <td>0.053551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTERN ASIA</th>\n",
       "      <td>613</td>\n",
       "      <td>13469.7</td>\n",
       "      <td>0.045510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTHERN EUROPE</th>\n",
       "      <td>819</td>\n",
       "      <td>18285.8</td>\n",
       "      <td>0.044789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EASTERN AFRICA</th>\n",
       "      <td>672</td>\n",
       "      <td>24116.9</td>\n",
       "      <td>0.027864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTERN EUROPE</th>\n",
       "      <td>500</td>\n",
       "      <td>19064.0</td>\n",
       "      <td>0.026227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORTHERN AFRICA</th>\n",
       "      <td>306</td>\n",
       "      <td>12366.3</td>\n",
       "      <td>0.024745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EASTERN EUROPE</th>\n",
       "      <td>726</td>\n",
       "      <td>29582.5</td>\n",
       "      <td>0.024542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIDDLE AFRICA</th>\n",
       "      <td>230</td>\n",
       "      <td>9496.8</td>\n",
       "      <td>0.024219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTHERN AFRICA</th>\n",
       "      <td>123</td>\n",
       "      <td>5954.3</td>\n",
       "      <td>0.020657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTH AMERICA</th>\n",
       "      <td>564</td>\n",
       "      <td>33494.1</td>\n",
       "      <td>0.016839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTHEAST ASIA</th>\n",
       "      <td>399</td>\n",
       "      <td>45336.1</td>\n",
       "      <td>0.008801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTERN AFRICA</th>\n",
       "      <td>513</td>\n",
       "      <td>58724.2</td>\n",
       "      <td>0.008736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAST ASIA</th>\n",
       "      <td>153</td>\n",
       "      <td>37537.3</td>\n",
       "      <td>0.004076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTH ASIA</th>\n",
       "      <td>676</td>\n",
       "      <td>265403.6</td>\n",
       "      <td>0.002547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 article_count  population  articles_per_capita\n",
       "region                                                         \n",
       "OCEANIA                     71       110.8             0.640794\n",
       "NORTHERN EUROPE            196      1194.5             0.164085\n",
       "CARIBBEAN                  215      1369.7             0.156969\n",
       "CENTRAL AMERICA            193      1477.5             0.130626\n",
       "CENTRAL ASIA               118      2203.5             0.053551\n",
       "WESTERN ASIA               613     13469.7             0.045510\n",
       "SOUTHERN EUROPE            819     18285.8             0.044789\n",
       "EASTERN AFRICA             672     24116.9             0.027864\n",
       "WESTERN EUROPE             500     19064.0             0.026227\n",
       "NORTHERN AFRICA            306     12366.3             0.024745\n",
       "EASTERN EUROPE             726     29582.5             0.024542\n",
       "MIDDLE AFRICA              230      9496.8             0.024219\n",
       "SOUTHERN AFRICA            123      5954.3             0.020657\n",
       "SOUTH AMERICA              564     33494.1             0.016839\n",
       "SOUTHEAST ASIA             399     45336.1             0.008801\n",
       "WESTERN AFRICA             513     58724.2             0.008736\n",
       "EAST ASIA                  153     37537.3             0.004076\n",
       "SOUTH ASIA                 676    265403.6             0.002547"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the population in each region and the number of politician articles in each region\n",
    "region_populations = politicians_score_df.groupby('region').sum().loc[:,'population']\n",
    "articles_by_region_df = politicians_score_df.groupby('region').count().loc[:,['B','article_title']]\n",
    "# Grouping both calculations together into one dataset\n",
    "articles_by_region_df['population'] = region_populations\n",
    "# Calculating the per-capita article count for each region\n",
    "articles_by_region_df = articles_by_region_df.loc[:,['article_title','population']].rename({'article_title':'article_count'},axis=1)\n",
    "articles_by_region_df['articles_per_capita'] = articles_by_region_df.article_count / articles_by_region_df.population\n",
    "# Displaying per-capita article counts in descending order\n",
    "articles_by_region_df.sort_values('articles_per_capita', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ce8ac-5ef2-47e0-b803-f6c584f50bc9",
   "metadata": {},
   "source": [
    "Once again, we can see that raw article values are highest for the major european and asian regions, but the per-capita article counts are highest in regions with small populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "67d17b19-37c1-4159-9ed1-c6e148c8024a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>high_quality</th>\n",
       "      <th>quality_per_capita</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NORTHERN EUROPE</th>\n",
       "      <td>1194.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.005860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARIBBEAN</th>\n",
       "      <td>1369.7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTHERN EUROPE</th>\n",
       "      <td>18285.8</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CENTRAL AMERICA</th>\n",
       "      <td>1477.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTHERN AFRICA</th>\n",
       "      <td>5954.3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTERN ASIA</th>\n",
       "      <td>13469.7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CENTRAL ASIA</th>\n",
       "      <td>2203.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EASTERN EUROPE</th>\n",
       "      <td>29582.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIDDLE AFRICA</th>\n",
       "      <td>9496.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTERN EUROPE</th>\n",
       "      <td>19064.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NORTHERN AFRICA</th>\n",
       "      <td>12366.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTH AMERICA</th>\n",
       "      <td>33494.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTHEAST ASIA</th>\n",
       "      <td>45336.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EASTERN AFRICA</th>\n",
       "      <td>24116.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTERN AFRICA</th>\n",
       "      <td>58724.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOUTH ASIA</th>\n",
       "      <td>265403.6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAST ASIA</th>\n",
       "      <td>37537.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OCEANIA</th>\n",
       "      <td>110.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 population  high_quality  quality_per_capita\n",
       "region                                                       \n",
       "NORTHERN EUROPE      1194.5             7            0.005860\n",
       "CARIBBEAN            1369.7             5            0.003650\n",
       "SOUTHERN EUROPE     18285.8            27            0.001477\n",
       "CENTRAL AMERICA      1477.5             2            0.001354\n",
       "SOUTHERN AFRICA      5954.3             4            0.000672\n",
       "WESTERN ASIA        13469.7             7            0.000520\n",
       "CENTRAL ASIA         2203.5             1            0.000454\n",
       "EASTERN EUROPE      29582.5            10            0.000338\n",
       "MIDDLE AFRICA        9496.8             3            0.000316\n",
       "WESTERN EUROPE      19064.0             4            0.000210\n",
       "NORTHERN AFRICA     12366.3             2            0.000162\n",
       "SOUTH AMERICA       33494.1             5            0.000149\n",
       "SOUTHEAST ASIA      45336.1             5            0.000110\n",
       "EASTERN AFRICA      24116.9             2            0.000083\n",
       "WESTERN AFRICA      58724.2             3            0.000051\n",
       "SOUTH ASIA         265403.6             3            0.000011\n",
       "EAST ASIA           37537.3             0            0.000000\n",
       "OCEANIA               110.8             0            0.000000"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting number of high quality politician articles (GA or FA) for each region\n",
    "high_quality_by_region_df = politicians_score_df.groupby('region').sum().loc[:,['population', 'high_quality']]\n",
    "# Calculating number of high quality articles per million people in each region\n",
    "high_quality_by_region_df['quality_per_capita'] = high_quality_by_region_df.high_quality / high_quality_by_region_df.population\n",
    "# Generating table of highest quality per capita regions\n",
    "high_quality_by_region_df.sort_values('quality_per_capita', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c93898-6bf1-4bbf-a553-4e22f6a1efd9",
   "metadata": {},
   "source": [
    "From this final table, however, we can at last see a clear bias in the quality of the articles on politicians put together on Wikipedia. Compared to the other regions, the european regions have substantially more high-quality articles and a relatively small or moderate population count that makes their high-quality article count per-capita absurdly larger than the other regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5640c40-3419-46c2-93a2-1d31ef8a81e4",
   "metadata": {},
   "source": [
    "### Part 5: Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f743ee-0f77-4c00-b335-974981d98139",
   "metadata": {},
   "source": [
    "Looking at the results of this analysis, several key insights stand out as being particularly worthy of note. Throughout this analysis, it could be seen that the articles from less well-known or financially influential countries were far less likely to be contructed with Wikipedia's tenets of quality. From the analyses of high-quality articles it can be seen that the bulk of high quality articles were for politicians in european regions, to a degree that cannot be explained by population alone. However, even the process of cleaning the datasets for use in assembling each table revealed the fact that politicians from less influential countries were far more likely to have their political accomplishments separated off into a small stub article separate from the article on their personal life. Perhaps unsurprisingly, Wikipedia has a noticable bias towards mainstream European politicians when it comes to the effort put into refining each article. Given that Wikipedia is curated by individuals driven by their own passion for the site, it is ultimately quite understandable that the politicians that are more influential, and thus more _visible_ in modern culture, would recieve a disproportionate amount of attention and effort on their articles.\n",
    "\n",
    "However, this presents an obvious issue for researchers seeking to use Wikipedia as a source of unbiased political history. Of course, any attempt to use Wikipedia's information without an acknowledgement of the inherent biases of crowdsourcing information is misguided to begin with. But the thoroughness with which Wikipedia catalogues information from politicians across the work nevertheless makes it a compelling source of data for a researcher seeking to compare political careers from different regions across the world. A researcher aiming to study the differences between a typical political career path in Britain vs in the United States vs in Pakistan may make the decision to use Wikipedia as a source of comprehensive data simply due to the number of politicians it has catalogued. However, the conclusions such a researcher may draw would likely end up skewed by the fact that the information, citations, and article structure for politicians outside of europe are simply worse than they are for those specific countries.\n",
    "\n",
    "Ultimately, any researcher attempting to use Wikipedia as a source of political career information will have to enrich the dataset to support their needs. While Wikipedia has a significant disparity in article quality, the details within ech article often come with specific details and citations for all articles greater than a stub. As such, a researcher could use Wikipedia as a baseline source to learn the basic details of a politician's life and actions, while supplementing the articles with data obtained from political science research in the country associated with each figure. As this very analysis demonstrates, Wikipedia articles can be effective sources for analysis when combined with outside datasets such as population data and when embelished by additional data from sources such as the ORES API. Despite its inconsistency across regions, it serves perfectly well as a dataset to merge other more meticulous (but less expansive) datasets onto.rved?\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "50e97518-2ea1-46f9-8f24-cf1ec37d28f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| region          |   population |   high_quality |   quality_per_capita |\n",
      "|:----------------|-------------:|---------------:|---------------------:|\n",
      "| NORTHERN EUROPE |       1194.5 |              7 |          0.00586019  |\n",
      "| CARIBBEAN       |       1369.7 |              5 |          0.00365043  |\n",
      "| SOUTHERN EUROPE |      18285.8 |             27 |          0.00147656  |\n",
      "| CENTRAL AMERICA |       1477.5 |              2 |          0.00135364  |\n",
      "| SOUTHERN AFRICA |       5954.3 |              4 |          0.000671783 |\n",
      "| WESTERN ASIA    |      13469.7 |              7 |          0.000519685 |\n",
      "| CENTRAL ASIA    |       2203.5 |              1 |          0.000453823 |\n",
      "| EASTERN EUROPE  |      29582.5 |             10 |          0.000338038 |\n",
      "| MIDDLE AFRICA   |       9496.8 |              3 |          0.000315896 |\n",
      "| WESTERN EUROPE  |      19064   |              4 |          0.00020982  |\n",
      "| NORTHERN AFRICA |      12366.3 |              2 |          0.00016173  |\n",
      "| SOUTH AMERICA   |      33494.1 |              5 |          0.00014928  |\n",
      "| SOUTHEAST ASIA  |      45336.1 |              5 |          0.000110287 |\n",
      "| EASTERN AFRICA  |      24116.9 |              2 |          8.29294e-05 |\n",
      "| WESTERN AFRICA  |      58724.2 |              3 |          5.10863e-05 |\n",
      "| SOUTH ASIA      |     265404   |              3 |          1.13035e-05 |\n",
      "| EAST ASIA       |      37537.3 |              0 |          0           |\n",
      "| OCEANIA         |        110.8 |              0 |          0           |\n"
     ]
    }
   ],
   "source": [
    "print(high_quality_by_region_df.sort_values('quality_per_capita', ascending=False).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70244773-5850-4ddd-9da3-e1583fba899c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
